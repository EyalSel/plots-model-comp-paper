{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.dont_write_bytecode = True\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "import single_node_profiles_cpp as snp\n",
    "import profiler_new\n",
    "import numpy as np\n",
    "from optimizer_new import BruteForceOptimizer, GreedyOptimizer\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "profs = snp.load_single_node_profiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'tf-resnet-feats',\n",
       " u'tf-log-reg',\n",
       " u'tf-kernel-svm',\n",
       " u'res50',\n",
       " u'inception',\n",
       " u'res152',\n",
       " u'alexnet']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inception\n"
     ]
    }
   ],
   "source": [
    "dag = profiler_new.get_logical_pipeline(\"pipeline_one\")\n",
    "with open(os.path.abspath(\"../results/e2e_profs_new_metrics/incep_1-logreg_1-ksvm_1-resnet_1-180307_232122.json\")) as f:\n",
    "    sample_run = json.load(f)\n",
    "print(dag.reference_node)\n",
    "scale_factors = profiler_new.get_node_scale_factors(sample_run, dag.reference_node)\n",
    "node_configs = profiler_new.get_node_configs_from_experiment(sample_run)\n",
    "def which_stage(model_name):\n",
    "    if model_name == \"tf-kernel-svm\" or model_name == \"tf-log-reg\":\n",
    "        return \"latency_stage\"\n",
    "    else:\n",
    "        return \"thru_stage\"\n",
    "node_profs = {name : profiler_new.NodeProfile(name, profs[name], which_stage(name)) for name, _ in node_configs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<profiler_new.NodeProfile at 0x157e4e0910>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inception = profiler_new.NodeProfile(\"inception\", profs[\"inception\"], \"thru_stage\")\n",
    "inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Service throughput lower than arrival rate!\n",
      "('tf-resnet-feats', 21.3752733357193, inf, {'inception': NodeConfig(inception, 1, v100, 1, 1, aws), 'tf-kernel-svm': NodeConfig(tf-kernel-svm, 1, none, 1, 1, aws), 'tf-resnet-feats': NodeConfig(tf-resnet-feats, 1, v100, 1, 2, aws), 'tf-log-reg': NodeConfig(tf-log-reg, 1, none, 1, 1, aws)})\n",
      "Service throughput lower than arrival rate!\n",
      "('tf-resnet-feats', 21.181563468426553, inf, {'inception': NodeConfig(inception, 1, v100, 1, 1, aws), 'tf-kernel-svm': NodeConfig(tf-kernel-svm, 1, none, 1, 1, aws), 'tf-resnet-feats': NodeConfig(tf-resnet-feats, 1, v100, 2.0, 1, aws), 'tf-log-reg': NodeConfig(tf-log-reg, 1, none, 1, 1, aws)})\n",
      "Upgrading bottleneck node tf-resnet-feats to NodeConfig(tf-resnet-feats, 1, v100, 1, 2, aws)\n",
      "Service throughput lower than arrival rate!\n",
      "('inception', 29.128397142857143, inf, {'inception': NodeConfig(inception, 1, v100, 1, 1, aws), 'tf-kernel-svm': NodeConfig(tf-kernel-svm, 1, none, 1, 1, aws), 'tf-resnet-feats': NodeConfig(tf-resnet-feats, 1, v100, 1, 3, aws), 'tf-log-reg': NodeConfig(tf-log-reg, 1, none, 1, 1, aws)})\n",
      "Service throughput lower than arrival rate!\n",
      "('inception', 29.128397142857143, inf, {'inception': NodeConfig(inception, 1, v100, 1, 1, aws), 'tf-kernel-svm': NodeConfig(tf-kernel-svm, 1, none, 1, 1, aws), 'tf-resnet-feats': NodeConfig(tf-resnet-feats, 1, v100, 2.0, 2, aws), 'tf-log-reg': NodeConfig(tf-log-reg, 1, none, 1, 1, aws)})\n",
      "Upgrading bottleneck node tf-resnet-feats to NodeConfig(tf-resnet-feats, 1, v100, 1, 3, aws)\n",
      "Service throughput lower than arrival rate!\n",
      "('tf-resnet-feats', 32.06291000357895, inf, {'inception': NodeConfig(inception, 1, v100, 1, 2, aws), 'tf-kernel-svm': NodeConfig(tf-kernel-svm, 1, none, 1, 1, aws), 'tf-resnet-feats': NodeConfig(tf-resnet-feats, 1, v100, 1, 3, aws), 'tf-log-reg': NodeConfig(tf-log-reg, 1, none, 1, 1, aws)})\n",
      "Service throughput lower than arrival rate!\n",
      "('tf-resnet-feats', 32.06291000357895, inf, {'inception': NodeConfig(inception, 1, v100, 2.0, 1, aws), 'tf-kernel-svm': NodeConfig(tf-kernel-svm, 1, none, 1, 1, aws), 'tf-resnet-feats': NodeConfig(tf-resnet-feats, 1, v100, 1, 3, aws), 'tf-log-reg': NodeConfig(tf-log-reg, 1, none, 1, 1, aws)})\n",
      "Upgrading bottleneck node inception to NodeConfig(inception, 1, v100, 1, 2, aws)\n",
      "Initializing maximum x coordinate\n",
      "Telescoping on x coordinate\n",
      "(65536.0, 131072.0, 98304.0, 4202.5497399891, 4213)\n",
      "(98304.0, 131072.0, 114688.0, 4902.97469665395, 4885)\n",
      "(98304.0, 114688.0, 106496.0, 4552.762218321525, 4538)\n",
      "(98304.0, 106496.0, 102400.0, 4377.655979155313, 4372)\n",
      "(98304.0, 102400.0, 100352.0, 4290.102859572206, 4297)\n",
      "(100352.0, 102400.0, 101376.0, 4333.87941936376, 4338)\n",
      "(101376.0, 102400.0, 101888.0, 4355.767699259536, 4358)\n",
      "(101888.0, 102400.0, 102144.0, 4366.711839207424, 4365)\n",
      "('tf-resnet-feats', 42.7505466714386, 2.6433960711189228, {'inception': NodeConfig(inception, 1, v100, 1, 2, aws), 'tf-kernel-svm': NodeConfig(tf-kernel-svm, 1, none, 1, 1, aws), 'tf-resnet-feats': NodeConfig(tf-resnet-feats, 1, v100, 1, 4, aws), 'tf-log-reg': NodeConfig(tf-log-reg, 1, none, 1, 1, aws)})\n",
      "Initializing maximum x coordinate\n",
      "Telescoping on x coordinate\n",
      "(2048.0, 4096.0, 3072.0, 178.9648720457143, 172)\n",
      "(2048.0, 3072.0, 2560.0, 149.13739337142857, 146)\n",
      "('inception', 58.256794285714285, 0.42478934293150572, {'inception': NodeConfig(inception, 1, v100, 1, 2, aws), 'tf-kernel-svm': NodeConfig(tf-kernel-svm, 1, none, 1, 1, aws), 'tf-resnet-feats': NodeConfig(tf-resnet-feats, 1, v100, 2.0, 3, aws), 'tf-log-reg': NodeConfig(tf-log-reg, 1, none, 1, 1, aws)})\n",
      "Response time below latency constraint! Finished optimizing for cost.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'inception': NodeConfig(inception, 1, v100, 1, 2, aws),\n",
       "  'tf-kernel-svm': NodeConfig(tf-kernel-svm, 1, none, 1, 1, aws),\n",
       "  'tf-log-reg': NodeConfig(tf-log-reg, 1, none, 1, 1, aws),\n",
       "  'tf-resnet-feats': NodeConfig(tf-resnet-feats, 1, v100, 1, 3, aws)},\n",
       " {'cost': 13.105499999999999,\n",
       "  'latency': 0.11822876000000002,\n",
       "  'throughput': 32.06291000357895},\n",
       " 0.42478934293150572)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from optimizer_new import BruteForceOptimizer, GreedyOptimizer\n",
    "opt = GreedyOptimizer(dag, scale_factors, node_profs)\n",
    "cloud = \"aws\"\n",
    "initial_config = {\"tf-resnet-feats\": profiler_new.NodeConfig(name=\"tf-resnet-feats\",\n",
    "                                                          num_cpus=1,\n",
    "                                                          gpu_type=\"v100\",\n",
    "                                                          batch_size=1,\n",
    "                                                          num_replicas=1,\n",
    "                                                          cloud=cloud),\n",
    "                  \"inception\": profiler_new.NodeConfig(name=\"inception\",\n",
    "                                                      num_cpus=1,\n",
    "                                                      gpu_type=\"v100\",\n",
    "                                                      batch_size=1,\n",
    "                                                      num_replicas=1,\n",
    "                                                      cloud=cloud),\n",
    "                  \"tf-log-reg\": profiler_new.NodeConfig(name=\"tf-log-reg\",\n",
    "                                                      num_cpus=1,\n",
    "                                                      gpu_type=\"none\",\n",
    "                                                      batch_size=1,\n",
    "                                                      num_replicas=1,\n",
    "                                                      cloud=cloud),\n",
    "                  \"tf-kernel-svm\": profiler_new.NodeConfig(name=\"tf-kernel-svm\",\n",
    "                                                      num_cpus=1,\n",
    "                                                      gpu_type=\"none\",\n",
    "                                                      batch_size=1,\n",
    "                                                      num_replicas=1,\n",
    "                                                      cloud=cloud),\n",
    "                 }\n",
    "# 24 ms mean inter-arrival time\n",
    "arrival_cached = np.cumsum(np.random.exponential(24, size=(40000)))\n",
    "opt.select_optimal_config(cloud, 0.5, 100, initial_config, arrival_cached, optimize_what=\"cost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "def brute_force_optimizer(dag, scale_factors, node_profs, cost_constraint, latency_constraint):\n",
    "    \"\"\"\n",
    "        This doesn't loo\n",
    "    \"\"\"\n",
    "    all_node_configs = [node_profs[node].enumerate_configs(max_replication_factor=3) for node in dag.nodes()]     \n",
    "    all_pipeline_configs = itertools.product(*all_node_configs)\n",
    "    num_valid_configs = 0\n",
    "    best_config = None\n",
    "    best_config_perf = None\n",
    "    cur_index = 0\n",
    "    for p_config in all_pipeline_configs:\n",
    "        cur_index += 1\n",
    "        if cur_index % 500 == 0:\n",
    "            print(\"Processed {}\".format(cur_index))\n",
    "        cur_node_configs = {n.name: n for n in p_config}\n",
    "        if not profiler.is_valid_pipeline_config(cur_node_configs):\n",
    "            continue\n",
    "        cur_config_perf = profiler.estimate_pipeline_performance_for_config(\n",
    "            dag, scale_factors, cur_node_configs, node_profs)\n",
    "        if cur_config_perf[\"latency\"] <= latency_constraint and cur_config_perf[\"cost\"] <= cost_constraint:\n",
    "            if best_config is None:\n",
    "                best_config = cur_node_configs\n",
    "                best_config_perf = cur_config_perf\n",
    "                print(\"Initializing config to {} ({})\".format(best_config, best_config_perf))\n",
    "            else:\n",
    "                if cur_config_perf[\"throughput\"] > best_config_perf[\"throughput\"]:\n",
    "                    best_config = cur_node_configs\n",
    "                    best_config_perf = cur_config_perf\n",
    "                    print(\"Updating config to {} ({})\".format(best_config, best_config_perf))\n",
    "        \n",
    "    return best_config, best_config_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "brute_force_optimizer(dag, scale_factors, node_profs, 7.0, 0.8)\n",
    "end = datetime.now()\n",
    "print(\"{}\".format((end-start).total_seconds()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "profiler.estimate_pipeline_performance_for_config(dag, scale_factors, node_configs, node_profs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "groups = profs[\"alexnet\"].groupby([\"cloud\",\"gpu_type\",\"num_cpus_per_replica\"])\n",
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for name, df in groups:\n",
    "    print(name, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
