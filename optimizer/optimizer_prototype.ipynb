{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import single_model_profiles as smp\n",
    "import profiler\n",
    "import end_to_end_profiles as e2e_profs\n",
    "import numpy as np\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "profs = smp.load_single_model_profiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['alexnet', 'res152', 'res18', 'res50', 'inception', 'tf-kernel-svm', 'tf-lang-detect', 'tf-log-reg', 'tf-lstm', 'tf-nmt', 'tf-resnet-feats'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dag = profiler.get_logical_pipeline(\"pipeline_three\")\n",
    "with open(os.path.abspath(\"../results/e2e_profs/systemx/resnet_cascade/slo_500ms/alex_1-r50_1-r152_2-171025_083730.json\")) as f:\n",
    "    sample_run = json.load(f)\n",
    "scale_factors = profiler.get_node_scale_factors(sample_run, dag.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ModelProfile(object):\n",
    "    \n",
    "    def __init__(self, profile, scale_factor):\n",
    "        self.profile = profile\n",
    "        self.scale_factor = scale_factor\n",
    "    \n",
    "    def estimate_performance(self, num_cpus, gpu_type, batch_size):\n",
    "        \"\"\"\n",
    "        Estimates the model's performance under the specified configuration.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        num_cpus : int\n",
    "            The number of virtual cpus allocated to model\n",
    "        gpu_type : str\n",
    "            Which type of GPU this model is using. Can be None, \"p100\", \"k80\", \"v100\".\n",
    "        batch_size : int\n",
    "            The batch size for the model\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        tuple : (p99_latency, throughput, cost)\n",
    "            Returns estimated latency, throughput, and cost for this configuration.\n",
    "            If there is not an exact batch size match, the profiler will perform linear\n",
    "            interpolation.\n",
    "            \n",
    "        Raises:\n",
    "        -------\n",
    "        A RuntimeException will be raised if the model has not been profiled under the requested configuration.\n",
    "        \"\"\"\n",
    "        resource_bundle_matches = self.profile[(self.profile.gpu_type == gpu_type)\n",
    "                                             & (self.profile.num_cpus_per_replica == num_cpus)]\n",
    "        resource_bundle_matches = resource_bundle_matches.sort_values(\"mean_batch_size\")\n",
    "        glb = resource_bundle_matches['mean_batch_size'] <= batch_size\n",
    "        lub = resource_bundle_matches['mean_batch_size'] >= batch_size\n",
    "        idx_glb = resource_bundle_matches.loc[resource_bundle_matches.index[glb], 'mean_batch_size'].idxmax()\n",
    "        idx_lub = resource_bundle_matches.loc[resource_bundle_matches.index[lub], 'mean_batch_size'].idxmin()\n",
    "        relevant_entries = resource_bundle_matches.loc[idx_glb:idx_lub]\n",
    "        assert np.all(np.diff(relevant_entries[\"mean_throughput_qps\"]) > 0)\n",
    "        estimated_thruput = np.interp(batch_size,\n",
    "                                      relevant_entries[\"mean_batch_size\"],\n",
    "                                      relevant_entries[\"mean_throughput_qps\"])\n",
    "        \n",
    "        assert np.all(np.diff(relevant_entries[\"p99_latency\"]) > 0)\n",
    "        estimated_latency = np.interp(batch_size,\n",
    "                                      relevant_entries[\"mean_batch_size\"],\n",
    "                                      relevant_entries[\"p99_latency\"])\n",
    "        # The cost for all the entries with the same resource bundle is the same,\n",
    "        # so we just get it from the first entry\n",
    "        cost = relevant_entries[\"cost\"].iloc[0]\n",
    "        return (estimated_latency, estimated_thruput, cost)\n",
    "        \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-92ff688b628a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_prof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelProfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"res50\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"res50\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_prof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"p100\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_cpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-62-06f1bdf3fd69>\u001b[0m in \u001b[0;36mestimate_performance\u001b[0;34m(self, num_cpus, gpu_type, batch_size)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0midx_lub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresource_bundle_matches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresource_bundle_matches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlub\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean_batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mrelevant_entries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresource_bundle_matches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_glb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx_lub\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevant_entries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mean_throughput_qps\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         estimated_thruput = np.interp(batch_size,\n\u001b[1;32m     41\u001b[0m                                       \u001b[0mrelevant_entries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mean_batch_size\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_prof = ModelProfile(profs[\"res50\"], scale_factors[\"res50\"])\n",
    "test_prof.estimate_performance(batch_size=6, gpu_type=\"p100\", num_cpus=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_cpus_per_replica</th>\n",
       "      <th>mean_throughput_qps</th>\n",
       "      <th>std_throughput_qps</th>\n",
       "      <th>p99_latency</th>\n",
       "      <th>mean_batch_size</th>\n",
       "      <th>cost</th>\n",
       "      <th>fname</th>\n",
       "      <th>cloud</th>\n",
       "      <th>gpu_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2</td>\n",
       "      <td>171.691247</td>\n",
       "      <td>2.764047</td>\n",
       "      <td>0.609447</td>\n",
       "      <td>26.784837</td>\n",
       "      <td>0.795</td>\n",
       "      <td>results-p100-2-32-180201_232825.json</td>\n",
       "      <td>gcp</td>\n",
       "      <td>p100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2</td>\n",
       "      <td>172.551915</td>\n",
       "      <td>0.879018</td>\n",
       "      <td>1.125017</td>\n",
       "      <td>44.753849</td>\n",
       "      <td>0.795</td>\n",
       "      <td>results-p100-2-48-180202_000055.json</td>\n",
       "      <td>gcp</td>\n",
       "      <td>p100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_cpus_per_replica  mean_throughput_qps  std_throughput_qps  \\\n",
       "58                     2           171.691247            2.764047   \n",
       "60                     2           172.551915            0.879018   \n",
       "\n",
       "    p99_latency  mean_batch_size   cost                                 fname  \\\n",
       "58     0.609447        26.784837  0.795  results-p100-2-32-180201_232825.json   \n",
       "60     1.125017        44.753849  0.795  results-p100-2-48-180202_000055.json   \n",
       "\n",
       "   cloud gpu_type  \n",
       "58   gcp     p100  \n",
       "60   gcp     p100  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_cpus_per_replica</th>\n",
       "      <th>mean_throughput_qps</th>\n",
       "      <th>std_throughput_qps</th>\n",
       "      <th>p99_latency</th>\n",
       "      <th>mean_batch_size</th>\n",
       "      <th>cost</th>\n",
       "      <th>fname</th>\n",
       "      <th>cloud</th>\n",
       "      <th>gpu_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2</td>\n",
       "      <td>56.892347</td>\n",
       "      <td>0.122212</td>\n",
       "      <td>0.108707</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.795</td>\n",
       "      <td>results-p100-2-1-180201_023311.json</td>\n",
       "      <td>gcp</td>\n",
       "      <td>p100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2</td>\n",
       "      <td>60.852290</td>\n",
       "      <td>0.160357</td>\n",
       "      <td>0.097816</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.795</td>\n",
       "      <td>results-p100-2-1-180201_054538.json</td>\n",
       "      <td>gcp</td>\n",
       "      <td>p100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2</td>\n",
       "      <td>116.630455</td>\n",
       "      <td>0.455269</td>\n",
       "      <td>0.065550</td>\n",
       "      <td>1.950210</td>\n",
       "      <td>0.795</td>\n",
       "      <td>results-p100-2-2-180201_060645.json</td>\n",
       "      <td>gcp</td>\n",
       "      <td>p100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2</td>\n",
       "      <td>150.366386</td>\n",
       "      <td>0.566909</td>\n",
       "      <td>0.092330</td>\n",
       "      <td>3.805082</td>\n",
       "      <td>0.795</td>\n",
       "      <td>results-p100-2-4-180201_062346.json</td>\n",
       "      <td>gcp</td>\n",
       "      <td>p100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2</td>\n",
       "      <td>105.351405</td>\n",
       "      <td>2.189242</td>\n",
       "      <td>0.524941</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.795</td>\n",
       "      <td>results-p100-2-8-180201_195554.json</td>\n",
       "      <td>gcp</td>\n",
       "      <td>p100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2</td>\n",
       "      <td>173.329049</td>\n",
       "      <td>2.126446</td>\n",
       "      <td>0.239299</td>\n",
       "      <td>11.993266</td>\n",
       "      <td>0.795</td>\n",
       "      <td>results-p100-2-12-180201_201136.json</td>\n",
       "      <td>gcp</td>\n",
       "      <td>p100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2</td>\n",
       "      <td>154.347975</td>\n",
       "      <td>2.686674</td>\n",
       "      <td>0.599024</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.795</td>\n",
       "      <td>results-p100-2-16-180201_215116.json</td>\n",
       "      <td>gcp</td>\n",
       "      <td>p100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2</td>\n",
       "      <td>170.635352</td>\n",
       "      <td>2.619203</td>\n",
       "      <td>0.496442</td>\n",
       "      <td>18.970265</td>\n",
       "      <td>0.795</td>\n",
       "      <td>results-p100-2-20-180201_220804.json</td>\n",
       "      <td>gcp</td>\n",
       "      <td>p100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2</td>\n",
       "      <td>171.259816</td>\n",
       "      <td>1.353511</td>\n",
       "      <td>0.762376</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.795</td>\n",
       "      <td>results-p100-2-24-180201_222522.json</td>\n",
       "      <td>gcp</td>\n",
       "      <td>p100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2</td>\n",
       "      <td>171.691247</td>\n",
       "      <td>2.764047</td>\n",
       "      <td>0.609447</td>\n",
       "      <td>26.784837</td>\n",
       "      <td>0.795</td>\n",
       "      <td>results-p100-2-32-180201_232825.json</td>\n",
       "      <td>gcp</td>\n",
       "      <td>p100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2</td>\n",
       "      <td>172.551915</td>\n",
       "      <td>0.879018</td>\n",
       "      <td>1.125017</td>\n",
       "      <td>44.753849</td>\n",
       "      <td>0.795</td>\n",
       "      <td>results-p100-2-48-180202_000055.json</td>\n",
       "      <td>gcp</td>\n",
       "      <td>p100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2</td>\n",
       "      <td>171.401321</td>\n",
       "      <td>1.631849</td>\n",
       "      <td>1.286694</td>\n",
       "      <td>49.558488</td>\n",
       "      <td>0.795</td>\n",
       "      <td>results-p100-2-64-180202_003751.json</td>\n",
       "      <td>gcp</td>\n",
       "      <td>p100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_cpus_per_replica  mean_throughput_qps  std_throughput_qps  \\\n",
       "51                     2            56.892347            0.122212   \n",
       "52                     2            60.852290            0.160357   \n",
       "55                     2           116.630455            0.455269   \n",
       "59                     2           150.366386            0.566909   \n",
       "62                     2           105.351405            2.189242   \n",
       "53                     2           173.329049            2.126446   \n",
       "54                     2           154.347975            2.686674   \n",
       "56                     2           170.635352            2.619203   \n",
       "57                     2           171.259816            1.353511   \n",
       "58                     2           171.691247            2.764047   \n",
       "60                     2           172.551915            0.879018   \n",
       "61                     2           171.401321            1.631849   \n",
       "\n",
       "    p99_latency  mean_batch_size   cost                                 fname  \\\n",
       "51     0.108707         1.000000  0.795   results-p100-2-1-180201_023311.json   \n",
       "52     0.097816         1.000000  0.795   results-p100-2-1-180201_054538.json   \n",
       "55     0.065550         1.950210  0.795   results-p100-2-2-180201_060645.json   \n",
       "59     0.092330         3.805082  0.795   results-p100-2-4-180201_062346.json   \n",
       "62     0.524941         8.000000  0.795   results-p100-2-8-180201_195554.json   \n",
       "53     0.239299        11.993266  0.795  results-p100-2-12-180201_201136.json   \n",
       "54     0.599024        16.000000  0.795  results-p100-2-16-180201_215116.json   \n",
       "56     0.496442        18.970265  0.795  results-p100-2-20-180201_220804.json   \n",
       "57     0.762376        24.000000  0.795  results-p100-2-24-180201_222522.json   \n",
       "58     0.609447        26.784837  0.795  results-p100-2-32-180201_232825.json   \n",
       "60     1.125017        44.753849  0.795  results-p100-2-48-180202_000055.json   \n",
       "61     1.286694        49.558488  0.795  results-p100-2-64-180202_003751.json   \n",
       "\n",
       "   cloud gpu_type  \n",
       "51   gcp     p100  \n",
       "52   gcp     p100  \n",
       "55   gcp     p100  \n",
       "59   gcp     p100  \n",
       "62   gcp     p100  \n",
       "53   gcp     p100  \n",
       "54   gcp     p100  \n",
       "56   gcp     p100  \n",
       "57   gcp     p100  \n",
       "58   gcp     p100  \n",
       "60   gcp     p100  \n",
       "61   gcp     p100  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = test_prof.estimate_performance(2, \"p100\", 16)\n",
    "matches = matches.sort_values(\"mean_batch_size\")\n",
    "glb = matches['mean_batch_size'] <= batch_size\n",
    "lub = matches['mean_batch_size'] >= batch_size\n",
    "idx_glb = matches.loc[matches.index[glb], 'mean_batch_size'].idxmax()\n",
    "idx_lub = matches.loc[matches.index[lub], 'mean_batch_size'].idxmin()\n",
    "display(matches.loc[idx_glb:idx_lub])\n",
    "matches\n",
    "\n",
    "\n",
    "# idx_glb, idx_lub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79499999999999993"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches[\"cost\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estimate_performance(logical_pipeline, scale_factors, single_model_profiles"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
