{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "import single_node_profiles_cpp as snp\n",
    "import profiler\n",
    "import end_to_end_profiles as e2e_profs\n",
    "import numpy as np\n",
    "from optimizer import BruteForceOptimizer, GreedyOptimizer\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "profs = snp.load_single_node_profiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dag = profiler.get_logical_pipeline(\"pipeline_one\")\n",
    "with open(os.path.abspath(\"../results_python_benchmarker/e2e_profs/systemx/image_driver_1/500ms/incep_1-logreg_1-ksvm_1-resnet_1-171221_091209.json\")) as f:\n",
    "    sample_run = json.load(f)\n",
    "scale_factors = profiler.get_node_scale_factors(sample_run, dag.reference_node)\n",
    "node_configs = profiler.get_node_configs_from_experiment(sample_run)\n",
    "node_profs = {}\n",
    "for name, _ in node_configs.items():\n",
    "    if name in [\"tf-log-reg\", \"tf-kernel-svm\"]:\n",
    "        node_profs[name] = profiler.NodeProfile(name, profs[name], \"latency_stage\")\n",
    "    else:\n",
    "        node_profs[name] = profiler.NodeProfile(name, profs[name], \"thru_stage\")\n",
    "\n",
    "\n",
    "# node_profs = {name : profiler.NodeProfile(name, profs[name]) for name, _ in node_configs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['inception', 'tf-log-reg', 'tf-kernel-svm', 'tf-resnet-feats'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_profs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upgrading bottleneck node tf-resnet-feats to NodeConfig(tf-resnet-feats, 1, k80, 2.0, 1, aws)\n",
      "Upgrading bottleneck node inception to NodeConfig(inception, 1, k80, 2.0, 1, aws)\n",
      "Upgrading bottleneck node tf-resnet-feats to NodeConfig(tf-resnet-feats, 1, k80, 3.0, 1, aws)\n",
      "Upgrading bottleneck node tf-resnet-feats to NodeConfig(tf-resnet-feats, 1, k80, 4.0, 1, aws)\n",
      "Upgrading bottleneck node tf-resnet-feats to NodeConfig(tf-resnet-feats, 1, k80, 8.0, 1, aws)\n",
      "Upgrading bottleneck node inception to NodeConfig(inception, 1, k80, 3.0, 1, aws)\n",
      "Upgrading bottleneck node tf-resnet-feats to NodeConfig(tf-resnet-feats, 1, k80, 12.0, 1, aws)\n",
      "Upgrading bottleneck node inception to NodeConfig(inception, 1, k80, 4.0, 1, aws)\n",
      "Upgrading bottleneck node tf-resnet-feats to NodeConfig(tf-resnet-feats, 1, k80, 16.0, 1, aws)\n",
      "Upgrading bottleneck node inception to NodeConfig(inception, 1, k80, 8.0, 1, aws)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'inception': NodeConfig(inception, 1, k80, 8.0, 1, aws),\n",
       "  'tf-kernel-svm': NodeConfig(tf-kernel-svm, 1, none, 1, 1, aws),\n",
       "  'tf-log-reg': NodeConfig(tf-log-reg, 1, none, 1, 1, aws),\n",
       "  'tf-resnet-feats': NodeConfig(tf-resnet-feats, 1, k80, 16.0, 1, aws)},\n",
       " {'cost': 1.534, 'latency': 0.39866122, 'throughput': 44.72536696343619})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = GreedyOptimizer(dag, scale_factors, node_profs)\n",
    "cloud = \"aws\"\n",
    "initial_config = {\"inception\": profiler.NodeConfig(name=\"inception\",\n",
    "                                                      num_cpus=1,\n",
    "                                                      gpu_type=\"k80\",\n",
    "                                                      batch_size=1,\n",
    "                                                      num_replicas=1,\n",
    "                                                      cloud=cloud),\n",
    "                  \"tf-resnet-feats\": profiler.NodeConfig(name=\"tf-resnet-feats\",\n",
    "                                                      num_cpus=1,\n",
    "                                                      gpu_type=\"k80\",\n",
    "                                                      batch_size=1,\n",
    "                                                      num_replicas=1,\n",
    "                                                      cloud=cloud),\n",
    "                  \"tf-log-reg\": profiler.NodeConfig(name=\"tf-log-reg\",\n",
    "                                                      num_cpus=1,\n",
    "                                                      gpu_type=\"none\",\n",
    "                                                      batch_size=1,\n",
    "                                                      num_replicas=1,\n",
    "                                                      cloud=cloud),\n",
    "                  \"tf-kernel-svm\": profiler.NodeConfig(name=\"tf-kernel-svm\",\n",
    "                                                      num_cpus=1,\n",
    "                                                      gpu_type=\"none\",\n",
    "                                                      batch_size=1,\n",
    "                                                      num_replicas=1,\n",
    "                                                      cloud=cloud),\n",
    "                 }\n",
    "opt.select_optimal_config(cloud, 0.5, 2, initial_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "node_profs[\"res152\"].plot_profile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, p in node_profs.items():\n",
    "    p.check_monotonicity()\n",
    "    r = p.plot_profile()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [True, True, False]\n",
    "for i, p in enumerate(b):\n",
    "    print(i,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = node_profs[\"alexnet\"]\n",
    "p.profile.iloc[7][\"mean_batch_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bundle, _ in r:\n",
    "    print(\"-\".join([str(b) for b in bundle]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opt = GreedyOptimizer(dag, scale_factors, node_profs)\n",
    "cloud = \"gcp\"\n",
    "initial_config = {\"tf\": profiler.NodeConfig(name=\"alexnet\",\n",
    "                                                      num_cpus=1,\n",
    "                                                      gpu_type=\"k80\",\n",
    "                                                      batch_size=1,\n",
    "                                                      num_replicas=1,\n",
    "                                                      cloud=cloud),\n",
    "                  \"res50\": profiler.NodeConfig(name=\"res50\",\n",
    "                                                      num_cpus=1,\n",
    "                                                      gpu_type=\"k80\",\n",
    "                                                          batch_size=1,\n",
    "                                                      num_replicas=1,\n",
    "                                                      cloud=cloud),\n",
    "                  \"res152\": profiler.NodeConfig(name=\"res152\",\n",
    "                                                      num_cpus=1,\n",
    "                                                      gpu_type=\"k80\",\n",
    "                                                      batch_size=1,\n",
    "                                                      num_replicas=1,\n",
    "                                                      cloud=cloud),\n",
    "                 }\n",
    "opt.select_optimal_config(cloud, 0.7, 50, initial_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "def brute_force_optimizer(dag, scale_factors, node_profs, cost_constraint, latency_constraint):\n",
    "    \"\"\"\n",
    "        This doesn't loo\n",
    "    \"\"\"\n",
    "    all_node_configs = [node_profs[node].enumerate_configs(max_replication_factor=3) for node in dag.nodes()]     \n",
    "    all_pipeline_configs = itertools.product(*all_node_configs)\n",
    "    num_valid_configs = 0\n",
    "    best_config = None\n",
    "    best_config_perf = None\n",
    "    cur_index = 0\n",
    "    for p_config in all_pipeline_configs:\n",
    "        cur_index += 1\n",
    "        if cur_index % 500 == 0:\n",
    "            print(\"Processed {}\".format(cur_index))\n",
    "        cur_node_configs = {n.name: n for n in p_config}\n",
    "        if not profiler.is_valid_pipeline_config(cur_node_configs):\n",
    "            continue\n",
    "        cur_config_perf = profiler.estimate_pipeline_performance_for_config(\n",
    "            dag, scale_factors, cur_node_configs, node_profs)\n",
    "        if cur_config_perf[\"latency\"] <= latency_constraint and cur_config_perf[\"cost\"] <= cost_constraint:\n",
    "            if best_config is None:\n",
    "                best_config = cur_node_configs\n",
    "                best_config_perf = cur_config_perf\n",
    "                print(\"Initializing config to {} ({})\".format(best_config, best_config_perf))\n",
    "            else:\n",
    "                if cur_config_perf[\"throughput\"] > best_config_perf[\"throughput\"]:\n",
    "                    best_config = cur_node_configs\n",
    "                    best_config_perf = cur_config_perf\n",
    "                    print(\"Updating config to {} ({})\".format(best_config, best_config_perf))\n",
    "        \n",
    "    return best_config, best_config_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "brute_force_optimizer(dag, scale_factors, node_profs, 7.0, 0.8)\n",
    "end = datetime.now()\n",
    "print(\"{}\".format((end-start).total_seconds()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "profiler.estimate_pipeline_performance_for_config(dag, scale_factors, node_configs, node_profs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = profs[\"alexnet\"].groupby([\"cloud\",\"gpu_type\",\"num_cpus_per_replica\"])\n",
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, df in groups:\n",
    "    print(name, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
